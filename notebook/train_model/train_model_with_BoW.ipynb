{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f05753a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>នាយិកា មជ្ឈមណ្ឌល សិទ្ធិ មនុស្ស កម្ពុជា អ្នកស្រ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ការឃុំ កញ្ញា សេង ធារី កាន់តែ យូរ រដ្ឋាភិបាល ហ៊...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ប្រភព បង្ហើប បន្ទប់ ខ្ទង់ ចំណាយ ជាង ១០ម៉ឺន ដុល...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956 បាន បង្ហាញ ផូស្វ័រ បាន ផ្ទេរ ដើម បែក អារ ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ដរាបណា មិន បាន តាំងចិត្ត ខិតខំ ប្រឹង រៀន ប្រឹង...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label\n",
       "0  នាយិកា មជ្ឈមណ្ឌល សិទ្ធិ មនុស្ស កម្ពុជា អ្នកស្រ...   neutral\n",
       "1  ការឃុំ កញ្ញា សេង ធារី កាន់តែ យូរ រដ្ឋាភិបាល ហ៊...  positive\n",
       "2  ប្រភព បង្ហើប បន្ទប់ ខ្ទង់ ចំណាយ ជាង ១០ម៉ឺន ដុល...   neutral\n",
       "3  1956 បាន បង្ហាញ ផូស្វ័រ បាន ផ្ទេរ ដើម បែក អារ ...   neutral\n",
       "4  ដរាបណា មិន បាន តាំងចិត្ត ខិតខំ ប្រឹង រៀន ប្រឹង...  negative"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"../../data/cleaned_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bac792c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Features and labels\n",
    "X = data['text']  # cleaned text\n",
    "y = data['label']      # labels\n",
    "\n",
    "# Split dataset: 80% train, 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y  # stratify keeps class distribution\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df2e88cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MultinomialNB ===\n",
      "Accuracy: 0.6431784107946027\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.49      0.52       651\n",
      "     neutral       0.46      0.06      0.11       184\n",
      "    positive       0.68      0.82      0.74      1166\n",
      "\n",
      "    accuracy                           0.64      2001\n",
      "   macro avg       0.57      0.46      0.46      2001\n",
      "weighted avg       0.62      0.64      0.61      2001\n",
      "\n",
      "--------------------------------------------------\n",
      "=== LogisticRegression ===\n",
      "Accuracy: 0.567216391804098\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.52      0.54      0.53       651\n",
      "     neutral       0.22      0.47      0.30       184\n",
      "    positive       0.76      0.60      0.67      1166\n",
      "\n",
      "    accuracy                           0.57      2001\n",
      "   macro avg       0.50      0.54      0.50      2001\n",
      "weighted avg       0.63      0.57      0.59      2001\n",
      "\n",
      "--------------------------------------------------\n",
      "=== LinearSVC ===\n",
      "Accuracy: 0.5822088955522239\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.51      0.51      0.51       651\n",
      "     neutral       0.20      0.29      0.24       184\n",
      "    positive       0.71      0.67      0.69      1166\n",
      "\n",
      "    accuracy                           0.58      2001\n",
      "   macro avg       0.48      0.49      0.48      2001\n",
      "weighted avg       0.60      0.58      0.59      2001\n",
      "\n",
      "--------------------------------------------------\n",
      "=== RandomForest ===\n",
      "Accuracy: 0.6291854072963519\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.56      0.37      0.44       651\n",
      "     neutral       0.25      0.09      0.13       184\n",
      "    positive       0.67      0.86      0.75      1166\n",
      "\n",
      "    accuracy                           0.63      2001\n",
      "   macro avg       0.49      0.44      0.44      2001\n",
      "weighted avg       0.59      0.63      0.59      2001\n",
      "\n",
      "--------------------------------------------------\n",
      "=== DecisionTree ===\n",
      "Accuracy: 0.5322338830584707\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.44      0.43      0.44       651\n",
      "     neutral       0.20      0.29      0.24       184\n",
      "    positive       0.67      0.63      0.65      1166\n",
      "\n",
      "    accuracy                           0.53      2001\n",
      "   macro avg       0.44      0.45      0.44      2001\n",
      "weighted avg       0.55      0.53      0.54      2001\n",
      "\n",
      "--------------------------------------------------\n",
      "=== GradientBoosting ===\n",
      "Accuracy: 0.6121939030484758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.15      0.25       651\n",
      "     neutral       0.00      0.00      0.00       184\n",
      "    positive       0.61      0.97      0.74      1166\n",
      "\n",
      "    accuracy                           0.61      2001\n",
      "   macro avg       0.44      0.37      0.33      2001\n",
      "weighted avg       0.59      0.61      0.51      2001\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# 2. Vectorize text using BoW\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# 3. Define models\n",
    "models = {\n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=500, class_weight='balanced'),\n",
    "    \"LinearSVC\": LinearSVC(class_weight='balanced', max_iter=1000),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(class_weight='balanced', random_state=42),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# 4. Train & evaluate\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_vec, y_train)\n",
    "    y_pred = model.predict(X_test_vec)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"=== {name} ===\")\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c5a46d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MultinomialNB ===\n",
      "Accuracy: 0.656671664167916\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.58      0.55      0.56       651\n",
      "     neutral       0.56      0.05      0.10       184\n",
      "    positive       0.69      0.81      0.75      1166\n",
      "\n",
      "    accuracy                           0.66      2001\n",
      "   macro avg       0.61      0.47      0.47      2001\n",
      "weighted avg       0.64      0.66      0.63      2001\n",
      "\n",
      "--------------------------------------------------\n",
      "=== LogisticRegression ===\n",
      "Accuracy: 0.5987006496751625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.52      0.55      0.53       651\n",
      "     neutral       0.26      0.39      0.31       184\n",
      "    positive       0.74      0.66      0.70      1166\n",
      "\n",
      "    accuracy                           0.60      2001\n",
      "   macro avg       0.51      0.53      0.51      2001\n",
      "weighted avg       0.63      0.60      0.61      2001\n",
      "\n",
      "--------------------------------------------------\n",
      "=== LinearSVC ===\n",
      "Accuracy: 0.6016991504247876\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.51      0.51       651\n",
      "     neutral       0.27      0.29      0.28       184\n",
      "    positive       0.72      0.70      0.71      1166\n",
      "\n",
      "    accuracy                           0.60      2001\n",
      "   macro avg       0.50      0.50      0.50      2001\n",
      "weighted avg       0.61      0.60      0.60      2001\n",
      "\n",
      "--------------------------------------------------\n",
      "=== RandomForest ===\n",
      "Accuracy: 0.6411794102948526\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.58      0.40      0.47       651\n",
      "     neutral       0.30      0.11      0.16       184\n",
      "    positive       0.68      0.86      0.76      1166\n",
      "\n",
      "    accuracy                           0.64      2001\n",
      "   macro avg       0.52      0.46      0.46      2001\n",
      "weighted avg       0.61      0.64      0.61      2001\n",
      "\n",
      "--------------------------------------------------\n",
      "=== DecisionTree ===\n",
      "Accuracy: 0.5372313843078461\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.46      0.48      0.47       651\n",
      "     neutral       0.17      0.28      0.21       184\n",
      "    positive       0.69      0.61      0.65      1166\n",
      "\n",
      "    accuracy                           0.54      2001\n",
      "   macro avg       0.44      0.46      0.44      2001\n",
      "weighted avg       0.57      0.54      0.55      2001\n",
      "\n",
      "--------------------------------------------------\n",
      "=== GradientBoosting ===\n",
      "Accuracy: 0.616191904047976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.16      0.26       651\n",
      "     neutral       0.00      0.00      0.00       184\n",
      "    positive       0.61      0.97      0.75      1166\n",
      "\n",
      "    accuracy                           0.62      2001\n",
      "   macro avg       0.44      0.38      0.34      2001\n",
      "weighted avg       0.59      0.62      0.52      2001\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# 2. Vectorize text using BoW + n-grams\n",
    "vectorizer = CountVectorizer(\n",
    "    ngram_range=(1, 2),   # unigram + bigram\n",
    "    min_df=2,             # ignore very rare words\n",
    "    max_df=0.9            # ignore very common words\n",
    ")\n",
    "\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# 3. Define models\n",
    "models = {\n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=500, class_weight='balanced'),\n",
    "    \"LinearSVC\": LinearSVC(class_weight='balanced', max_iter=1000),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(class_weight='balanced', random_state=42),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# 4. Train & evaluate\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_vec, y_train)\n",
    "    y_pred = model.predict(X_test_vec)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"=== {name} ===\")\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"-\" * 50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wr-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
