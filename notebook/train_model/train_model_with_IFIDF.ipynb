{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7145b0d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>នាយិកា មជ្ឈមណ្ឌល សិទ្ធិ មនុស្ស កម្ពុជា អ្នកស្រ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ការឃុំ កញ្ញា សេង ធារី កាន់តែ យូរ រដ្ឋាភិបាល ហ៊...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ប្រភព បង្ហើប បន្ទប់ ខ្ទង់ ចំណាយ ជាង ១០ម៉ឺន ដុល...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956 បាន បង្ហាញ ផូស្វ័រ បាន ផ្ទេរ ដើម បែក អារ ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ដរាបណា មិន បាន តាំងចិត្ត ខិតខំ ប្រឹង រៀន ប្រឹង...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label\n",
       "0  នាយិកា មជ្ឈមណ្ឌល សិទ្ធិ មនុស្ស កម្ពុជា អ្នកស្រ...   neutral\n",
       "1  ការឃុំ កញ្ញា សេង ធារី កាន់តែ យូរ រដ្ឋាភិបាល ហ៊...  positive\n",
       "2  ប្រភព បង្ហើប បន្ទប់ ខ្ទង់ ចំណាយ ជាង ១០ម៉ឺន ដុល...   neutral\n",
       "3  1956 បាន បង្ហាញ ផូស្វ័រ បាន ផ្ទេរ ដើម បែក អារ ...   neutral\n",
       "4  ដរាបណា មិន បាន តាំងចិត្ត ខិតខំ ប្រឹង រៀន ប្រឹង...  negative"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"../../data/cleaned_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdc085b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Features and labels\n",
    "X = data['text']  # cleaned text\n",
    "y = data['label']      # labels\n",
    "\n",
    "# Split dataset: 80% train, 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y  # stratify keeps class distribution\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d2d049d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MultinomialNB ===\n",
      "Accuracy: 0.616191904047976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.16      0.26       651\n",
      "     neutral       0.00      0.00      0.00       184\n",
      "    positive       0.61      0.97      0.75      1166\n",
      "\n",
      "    accuracy                           0.62      2001\n",
      "   macro avg       0.43      0.38      0.34      2001\n",
      "weighted avg       0.57      0.62      0.52      2001\n",
      "\n",
      "--------------------------------------------------\n",
      "=== LogisticRegression ===\n",
      "Accuracy: 0.5812093953023488\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.54      0.56      0.55       651\n",
      "     neutral       0.21      0.44      0.29       184\n",
      "    positive       0.76      0.62      0.68      1166\n",
      "\n",
      "    accuracy                           0.58      2001\n",
      "   macro avg       0.50      0.54      0.51      2001\n",
      "weighted avg       0.64      0.58      0.60      2001\n",
      "\n",
      "--------------------------------------------------\n",
      "=== LinearSVC ===\n",
      "Accuracy: 0.6021989005497251\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.54      0.51      0.52       651\n",
      "     neutral       0.24      0.32      0.27       184\n",
      "    positive       0.72      0.70      0.71      1166\n",
      "\n",
      "    accuracy                           0.60      2001\n",
      "   macro avg       0.50      0.51      0.50      2001\n",
      "weighted avg       0.61      0.60      0.61      2001\n",
      "\n",
      "--------------------------------------------------\n",
      "=== RandomForest ===\n",
      "Accuracy: 0.6316841579210395\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.31      0.41       651\n",
      "     neutral       0.25      0.08      0.12       184\n",
      "    positive       0.65      0.90      0.76      1166\n",
      "\n",
      "    accuracy                           0.63      2001\n",
      "   macro avg       0.50      0.43      0.43      2001\n",
      "weighted avg       0.60      0.63      0.58      2001\n",
      "\n",
      "--------------------------------------------------\n",
      "=== DecisionTree ===\n",
      "Accuracy: 0.5252373813093453\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.43      0.44      0.43       651\n",
      "     neutral       0.19      0.28      0.23       184\n",
      "    positive       0.67      0.61      0.64      1166\n",
      "\n",
      "    accuracy                           0.53      2001\n",
      "   macro avg       0.43      0.44      0.43      2001\n",
      "weighted avg       0.55      0.53      0.54      2001\n",
      "\n",
      "--------------------------------------------------\n",
      "=== GradientBoosting ===\n",
      "Accuracy: 0.6156921539230384\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.17      0.27       651\n",
      "     neutral       0.33      0.02      0.04       184\n",
      "    positive       0.61      0.96      0.75      1166\n",
      "\n",
      "    accuracy                           0.62      2001\n",
      "   macro avg       0.54      0.38      0.35      2001\n",
      "weighted avg       0.61      0.62      0.53      2001\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "# 2. Vectorize text\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# 3. Define models\n",
    "models = {\n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=500, class_weight='balanced'),\n",
    "    \"LinearSVC\": LinearSVC(class_weight='balanced', max_iter=1000),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(class_weight='balanced', random_state=42),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# 4. Train & evaluate\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_vec, y_train)\n",
    "    y_pred = model.predict(X_test_vec)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"=== {name} ===\")\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"-\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b97a3652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MultinomialNB ===\n",
      "Accuracy: 0.6291854072963519\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.18      0.30       651\n",
      "     neutral       0.00      0.00      0.00       184\n",
      "    positive       0.62      0.98      0.76      1166\n",
      "\n",
      "    accuracy                           0.63      2001\n",
      "   macro avg       0.46      0.39      0.35      2001\n",
      "weighted avg       0.60      0.63      0.54      2001\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\I5\\WR_Project\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\I5\\WR_Project\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\I5\\WR_Project\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LogisticRegression ===\n",
      "Accuracy: 0.6226886556721639\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.55      0.59      0.57       651\n",
      "     neutral       0.27      0.41      0.33       184\n",
      "    positive       0.77      0.67      0.72      1166\n",
      "\n",
      "    accuracy                           0.62      2001\n",
      "   macro avg       0.53      0.56      0.54      2001\n",
      "weighted avg       0.65      0.62      0.63      2001\n",
      "\n",
      "--------------------------------------------------\n",
      "=== LinearSVC ===\n",
      "Accuracy: 0.6301849075462269\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.54      0.51      0.53       651\n",
      "     neutral       0.30      0.27      0.28       184\n",
      "    positive       0.72      0.75      0.74      1166\n",
      "\n",
      "    accuracy                           0.63      2001\n",
      "   macro avg       0.52      0.51      0.52      2001\n",
      "weighted avg       0.62      0.63      0.63      2001\n",
      "\n",
      "--------------------------------------------------\n",
      "=== RandomForest ===\n",
      "Accuracy: 0.6416791604197901\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.34      0.43       651\n",
      "     neutral       0.26      0.08      0.12       184\n",
      "    positive       0.67      0.90      0.77      1166\n",
      "\n",
      "    accuracy                           0.64      2001\n",
      "   macro avg       0.51      0.44      0.44      2001\n",
      "weighted avg       0.61      0.64      0.60      2001\n",
      "\n",
      "--------------------------------------------------\n",
      "=== DecisionTree ===\n",
      "Accuracy: 0.5217391304347826\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.44      0.47      0.45       651\n",
      "     neutral       0.18      0.27      0.22       184\n",
      "    positive       0.67      0.59      0.63      1166\n",
      "\n",
      "    accuracy                           0.52      2001\n",
      "   macro avg       0.43      0.44      0.43      2001\n",
      "weighted avg       0.55      0.52      0.53      2001\n",
      "\n",
      "--------------------------------------------------\n",
      "=== GradientBoosting ===\n",
      "Accuracy: 0.6231884057971014\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.19      0.30       651\n",
      "     neutral       0.33      0.02      0.03       184\n",
      "    positive       0.62      0.96      0.75      1166\n",
      "\n",
      "    accuracy                           0.62      2001\n",
      "   macro avg       0.55      0.39      0.36      2001\n",
      "weighted avg       0.62      0.62      0.54      2001\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# 2. Vectorize text (TF-IDF + n-gram)\n",
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),   # (n-gram) unigram + bigram\n",
    "    min_df=2,             # remove rare words\n",
    "    max_df=0.9            # remove too frequent words\n",
    ")\n",
    "\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "# 3. Define models\n",
    "models = {\n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=500, class_weight='balanced'),\n",
    "    \"LinearSVC\": LinearSVC(class_weight='balanced', max_iter=1000),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(class_weight='balanced', random_state=42),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# 4. Train & evaluate\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_vec, y_train)\n",
    "    y_pred = model.predict(X_test_vec)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"=== {name} ===\")\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"-\" * 50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wr-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
